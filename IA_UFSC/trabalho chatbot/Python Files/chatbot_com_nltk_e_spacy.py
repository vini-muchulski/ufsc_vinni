# -*- coding: utf-8 -*-
"""Chatbot com NLTK e spaCy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Us8HZkrGy-WZwJHHKS2rlAZm629o3Wnu

# main
"""

!pip install nltk spacy scikit-learn -q

!python -m spacy download pt_core_news_sm

!python -m nltk.download stopwords

import nltk
nltk.download('rslp')

import nltk
nltk.download('stopwords')

import json
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import RSLPStemmer
import spacy

nlp = spacy.load("pt_core_news_sm")

with open("perguntas_astronomia_langchain.json", "r", encoding="utf-8") as f:
    dados = json.load(f)

perguntas = [item["pergunta"] for item in dados]
respostas = [item["resposta"] for item in dados]

# Função de pré-processamento combinando NLTK e spaCy
# Remover pontuação e converter para minúsculas (usando regex)
# Tokenização e lematização com spaCy
# Remover stopwords com NLTK

# Stemming com NLTK (opcional, dependendo da necessidade)

def preprocessar(texto):

    texto = re.sub(r'[^\w\s]', '', texto.lower())


    doc = nlp(texto)
    tokens = [token.lemma_ for token in doc]


    stop_words = set(stopwords.words("portuguese"))
    tokens = [token for token in tokens if token not in stop_words]

    stemmer = RSLPStemmer()
    tokens = [stemmer.stem(token) for token in tokens]

    return " ".join(tokens)


perguntas_processadas = [preprocessar(pergunta) for pergunta in perguntas]

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(perguntas_processadas)

def obter_resposta(pergunta):
    pergunta_processada = preprocessar(pergunta)
    vetor_pergunta = vectorizer.transform([pergunta_processada])

    # Calcular similaridade com todas as perguntas
    similaridades = cosine_similarity(vetor_pergunta, X)
    indice_mais_similar = similaridades.argmax()

    return respostas[indice_mais_similar]

pergunta_usuario = " Fale sobre a formação da Lua."
resposta = obter_resposta(pergunta_usuario)
print(f"Pergunta: {pergunta_usuario}\nResposta: {resposta}")

pergunta_usuario = "Por que a Lua tem fases?"
resposta = obter_resposta(pergunta_usuario)
print(f"Pergunta: {pergunta_usuario}\nResposta: {resposta}")

pergunta_usuario = "O que foi  o programa Apollo?"
resposta = obter_resposta(pergunta_usuario)
print(f"Pergunta: {pergunta_usuario}\nResposta: {resposta}")

pergunta_usuario = "Fale sobre Marte?"
resposta = obter_resposta(pergunta_usuario)
print(f"Pergunta: {pergunta_usuario}\nResposta: {resposta}")

pergunta_usuario = "Fale sobre supernovas ?"
resposta = obter_resposta(pergunta_usuario)
print(f"Pergunta: {pergunta_usuario}\nResposta: {resposta}")

pergunta_usuario = "o que é Saturno ?" #"Fale sobre Saturno?"
resposta = obter_resposta(pergunta_usuario)
print(f"Pergunta: {pergunta_usuario}\nResposta: {resposta}")

# Usar embeddings do spaCy
doc_pergunta = nlp(preprocessar(pergunta_usuario))
docs_dataset = [nlp(preprocessar(p)) for p in perguntas]
similaridades = [doc_pergunta.similarity(doc) for doc in docs_dataset]
indice_mais_similar = similaridades.index(max(similaridades))